ethics and bias in ml

the moral grey space of AI decisions
	building AI applications for general use carry an added burden of consideration and responsibility on the part of the developers
	waze: route ppl away from poor neighborhoods bc of crime? unintended consequences of that
	self driving cars: if the car needs to swerve, which way? into what other vehicle (smallest, largest) should it? 
	there are serious ethical consequences to using these tools adn they should be taken seriously
6 types of ai bias to be aware of
	historical: using historical data that contained a "bias" in some way: amazon cv screener: trained on 10 years of amazon resumes, mostly male, so moving forward the model tended to prefer male resumes
	sample: example: text to speech being trained on audio books: narrators are mostly white men, which is a particular speech patten out of many in US, so the model performed worse on other ethnicities 
	label: pictures you show an image recognizer aren't varied enough: e.g. pics of a lion only face on, so model can't tell that the profile of a lion is a lion
	aggregation: grouping different groups' outcomes into one "outcome", ignoring the granularity, leads to over generalizing, possibly falsely representing certain groups' outcomes or experiences
	confirmation: ignore the results I don't agree with, give priority to the ones that fit my pre-existing worldview
	evaluation: test model on niche group, expect results to scale with increased diverity of data
navigating the legal landscape: ai and current laws
	main challenges of ai:
		data privacy
		intellectual property
		liability
		ai ethics and bias
overview of global ai regulatory developments
	eu, canada, us, brazil, and more are rolling out regulatory frameworks
	companies can get ahead by being great at risk identication and mitigation of its highest-risk systems
what is ethical ai and how can companies achieve it? 
	while govt intervetion will be necessary, companies themselves must bear much of the burden
	ethical AI is not a list of ten commandments, it's more complicated.
	having someone overseeing the building of a program (ai ethics officer, for example) is helpful
	conducting risk assessments on models could be good
	checklists that front-line data scientists have to fill out could be good
ethical issues of facial recognition technology
	facial recognition isn't perfect, it performs worst on minorities that whites
	the impact of this current reality varies on the use case. in law enforcement decisions, it could be very impactful 

	
	
	
	