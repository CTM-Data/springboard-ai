{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzr5Eo_qxHQi"
      },
      "source": [
        "# Mini Project: Build a Machine Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NvUsqw8xg26"
      },
      "source": [
        "## Predict Total Fare on the NYC Taxi Dataset\n",
        "\n",
        "Welcome to the NYC Taxi Fare Prediction project! In this Colab, we will continue using the NYC Taxi Dataset to predict the fare amount for taxi rides using a subset of available features. We will go through three main stages: building a baseline model, creating a full model, and performing hyperparameter tuning to enhance our predictions.\n",
        "\n",
        "Now that you've completed exploratory data analysis on this dataset you should have a good understanding of the feature space.\n",
        "\n",
        "## Project Objectives\n",
        "\n",
        "The primary objectives of this project are as follows:\n",
        "\n",
        "Baseline Model: We will start by building a simple baseline model to establish a benchmark for our predictions. This model will serve as a starting point to compare the performance of our subsequent models.\n",
        "\n",
        "Full Model: Next, we will develop a more comprehensive model that leverages machine learning techniques to improve prediction accuracy. We will use Scikit-Learn's model pipeline to build a framework that enables rapid experimentation.\n",
        "\n",
        "Hyperparameter Tuning: Lastly, we will optimize our full model by fine-tuning its hyperparameters. By systematically adjusting the parameters that control model behavior, we aim to achieve the best possible performance for our prediction task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lbJFWLELlI6N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJtGZwwG2WTW"
      },
      "source": [
        "Load the NYC taxi dataset into a Pandas DataFrame and do a few basic checks to ensure the data is loaded properly. Note, there are several months of data that can be used. For simplicity, use the Yellow Taxi 2022-01 parquet file [here](https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet). Here are your tasks:\n",
        "\n",
        "  1. Load the `yellow_tripdata_2022-01.parquet` file into Pandas.\n",
        "  2. Print the first 5 rows of data.\n",
        "  3. Drop any rows of data that contain NULL values.\n",
        "  4. Create a new feature, 'trip_duration' that captures the duration of the trip in minutes.\n",
        "  5. Create a varible named 'target_variable' to store the name of the thing we're trying to predict, 'total_amount'.\n",
        "  6. Create a list called 'feature_cols' containing the feature names that we'll be using to predict our target variable. The list should contain 'VendorID', 'trip_distance', 'payment_type', 'PULocationID', 'DOLocationID', and 'trip_duration'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "db--eb8zlNNg"
      },
      "outputs": [],
      "source": [
        "# Load the dataset into a pandas DataFrame (from https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
        "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TslBuHoXl_o1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>tpep_pickup_datetime</th>\n",
              "      <th>tpep_dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>PULocationID</th>\n",
              "      <th>DOLocationID</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "      <th>congestion_surcharge</th>\n",
              "      <th>airport_fee</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2022-01-01 00:35:40</td>\n",
              "      <td>2022-01-01 00:53:29</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.80</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>142</td>\n",
              "      <td>236</td>\n",
              "      <td>1</td>\n",
              "      <td>14.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>21.95</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2022-01-01 00:33:43</td>\n",
              "      <td>2022-01-01 00:42:07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>236</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>13.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2022-01-01 00:53:21</td>\n",
              "      <td>2022-01-01 01:02:19</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.97</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>166</td>\n",
              "      <td>166</td>\n",
              "      <td>1</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>10.56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2022-01-01 00:25:21</td>\n",
              "      <td>2022-01-01 00:35:23</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>114</td>\n",
              "      <td>68</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>11.80</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2022-01-01 00:36:48</td>\n",
              "      <td>2022-01-01 01:14:20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>68</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>23.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>30.30</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
              "0         1  2022-01-01 00:35:40   2022-01-01 00:53:29              2.0   \n",
              "1         1  2022-01-01 00:33:43   2022-01-01 00:42:07              1.0   \n",
              "2         2  2022-01-01 00:53:21   2022-01-01 01:02:19              1.0   \n",
              "3         2  2022-01-01 00:25:21   2022-01-01 00:35:23              1.0   \n",
              "4         2  2022-01-01 00:36:48   2022-01-01 01:14:20              1.0   \n",
              "\n",
              "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
              "0           3.80         1.0                  N           142           236   \n",
              "1           2.10         1.0                  N           236            42   \n",
              "2           0.97         1.0                  N           166           166   \n",
              "3           1.09         1.0                  N           114            68   \n",
              "4           4.30         1.0                  N            68           163   \n",
              "\n",
              "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
              "0             1         14.5    3.0      0.5        3.65           0.0   \n",
              "1             1          8.0    0.5      0.5        4.00           0.0   \n",
              "2             1          7.5    0.5      0.5        1.76           0.0   \n",
              "3             2          8.0    0.5      0.5        0.00           0.0   \n",
              "4             1         23.5    0.5      0.5        3.00           0.0   \n",
              "\n",
              "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
              "0                    0.3         21.95                   2.5          0.0  \n",
              "1                    0.3         13.30                   0.0          0.0  \n",
              "2                    0.3         10.56                   0.0          0.0  \n",
              "3                    0.3         11.80                   2.5          0.0  \n",
              "4                    0.3         30.30                   2.5          0.0  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first few rows of the dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4ybS7HV6HHQL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2463931, 19)\n",
            "(2392428, 19)\n"
          ]
        }
      ],
      "source": [
        "# Drop rows with missing values.\n",
        "print(df.shape)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZC4p9PEjnSm8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0   0 days 00:17:49\n",
              "1   0 days 00:08:24\n",
              "2   0 days 00:08:58\n",
              "3   0 days 00:10:02\n",
              "4   0 days 00:37:32\n",
              "Name: trip_duration, dtype: timedelta64[us]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create new feature, 'trip_duration'.\n",
        "df['trip_duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
        "df.trip_duration.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "R5d84tINrG9d"
      },
      "outputs": [],
      "source": [
        "# Create a list called feature_col to store column names\n",
        "feature_cols = ['VendorID', 'trip_distance', 'payment_type', 'PULocationID', 'DOLocationID', 'trip_duration']\n",
        "target_variable = 'total_amount'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq2kgevn51LY"
      },
      "source": [
        "Splitting a dataset into training and test sets is a crucial step in machine learning model development. It allows us to evaluate the performance and generalization ability of our models accurately. The training set is used to train the model, while the test set serves as an independent sample for evaluating its performance.\n",
        "\n",
        "1. **Model Training**: The training set is used to fit the model, allowing it to learn the underlying patterns and relationships between the features and the target variable. By exposing the model to a diverse range of examples in the training set, it can capture the underlying structure of the data.\n",
        "\n",
        "2. **Model Evaluation**: The test set, which is independent of the training set, is crucial for evaluating how well the trained model generalizes to unseen data. It provides an unbiased assessment of the model's performance on new instances. By measuring the model's accuracy, precision, recall, or other evaluation metrics on the test set, we can estimate how well the model will perform on unseen data.\n",
        "\n",
        "3. **Preventing Overfitting**: Overfitting occurs when a model learns the training data's noise and idiosyncrasies instead of the underlying patterns. By evaluating the model on the test set, we can identify if the model is overfitting. If the model performs significantly worse on the test set compared to the training set, it indicates overfitting. In such cases, we might need to adjust the model, feature selection, or regularization techniques to improve generalization.\n",
        "\n",
        "4. **Hyperparameter Tuning**: Splitting the dataset allows us to perform hyperparameter tuning on the model. Hyperparameters are configuration settings that control the learning process, such as learning rate, regularization strength, or the number of hidden layers in a neural network. By using a validation set (often created from a portion of the training set), we can iteratively adjust the hyperparameters and select the best combination that maximizes the model's performance on the validation set. The final evaluation on the test set provides an unbiased estimate of the model's performance.\n",
        "\n",
        "By splitting the dataset into training and test sets, we can ensure that our models are both well-trained and accurately evaluated. This separation helps us understand how the model will perform on new, unseen data, which is critical for assessing its effectiveness and making informed decisions about its deployment.\n",
        "\n",
        "Here is your task:\n",
        "\n",
        "  1. Use Scikit-Learn's [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split the data into training and test sets. Don't forget to set the random state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "grdbA-I6rMGC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>PULocationID</th>\n",
              "      <th>DOLocationID</th>\n",
              "      <th>trip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>710762</th>\n",
              "      <td>1</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>75</td>\n",
              "      <td>0 days 00:06:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716687</th>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>161</td>\n",
              "      <td>0 days 00:06:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034482</th>\n",
              "      <td>2</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>231</td>\n",
              "      <td>0 days 00:08:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938972</th>\n",
              "      <td>2</td>\n",
              "      <td>0.72</td>\n",
              "      <td>2</td>\n",
              "      <td>249</td>\n",
              "      <td>249</td>\n",
              "      <td>0 days 00:04:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989477</th>\n",
              "      <td>2</td>\n",
              "      <td>1.77</td>\n",
              "      <td>1</td>\n",
              "      <td>142</td>\n",
              "      <td>162</td>\n",
              "      <td>0 days 00:11:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         VendorID  trip_distance  payment_type  PULocationID  DOLocationID  \\\n",
              "710762          1           1.20             1           151            75   \n",
              "716687          1           1.00             1           107           161   \n",
              "2034482         2           1.25             1            13           231   \n",
              "938972          2           0.72             2           249           249   \n",
              "989477          2           1.77             1           142           162   \n",
              "\n",
              "          trip_duration  \n",
              "710762  0 days 00:06:03  \n",
              "716687  0 days 00:06:40  \n",
              "2034482 0 days 00:08:10  \n",
              "938972  0 days 00:04:52  \n",
              "989477  0 days 00:11:24  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[feature_cols], df[target_variable], random_state=0)\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIAhf_oA7PGx"
      },
      "source": [
        "The importance of a baseline model, even if it uses a simple strategy like always predicting the mean, cannot be understated. Here's why a baseline model is valuable:\n",
        "\n",
        "1. **Performance Comparison**: A baseline model serves as a reference point for evaluating the performance of more sophisticated models. By establishing a simple yet reasonable baseline, we can determine whether our advanced models offer any significant improvement over this basic approach. It helps us set realistic expectations and gauge the effectiveness of our efforts.\n",
        "\n",
        "2. **Model Complexity**: A baseline model provides insight into the complexity required to solve the prediction task. If a simple strategy like predicting the median performs reasonably well, it suggests that the problem might not necessitate complex modeling techniques. Conversely, if the baseline model performs poorly, it indicates the presence of more intricate patterns that need to be captured by more sophisticated models.\n",
        "\n",
        "3. **Minimum Performance Requirement**: A baseline model can establish a minimum performance requirement for a predictive task. If we cannot outperform the baseline, it suggests that our models have failed to capture even the most fundamental relationships within the data. In such cases, we may need to revisit our data preprocessing steps, feature engineering techniques, or consider other external factors affecting the task.\n",
        "\n",
        "4. **Identifying Data Issues**: A baseline model can help identify potential issues within the dataset. If the baseline model performs poorly, it may indicate problems like missing values, outliers, or data inconsistencies. These issues can be further investigated and resolved to improve the overall model performance.\n",
        "\n",
        "While a baseline model like always predicting the median may not offer the highest prediction accuracy, its importance lies in its role as a starting point for model development and evaluation. It provides a solid foundation for comparing and assessing the performance of more complex models, ensuring that any improvements made are meaningful and significant.\n",
        "\n",
        "Here is your task:\n",
        "\n",
        "  1. Create a model that always predicts the mean total fare of the training dataset. Use Scikit-Learn's [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) to evaluate this model. Is it any good?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6vV1UsNTFX22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  18.852689184376704,\n",
              "  ...]]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a baseline for mean absolute error of total amount\n",
        "\n",
        "def predict_fare_mean(X_test):\n",
        "    mean = y_train.mean()\n",
        "    n = len(X_train)\n",
        "    return [[mean] * n]\n",
        "\n",
        "predict_fare_mean(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCKDGKpg8MVb"
      },
      "source": [
        "With a baseline metric in place, we can try to build a machine learning model. Obviously, if the model can't beat the baseline then there are some major issues to be resolved.\n",
        "\n",
        "It's always a good idea to start with a simple machine learning model, like linear regression, and build upon it if necessary.\n",
        "\n",
        "Here are your tasks:\n",
        "\n",
        "  1. Use Scikit-Learn's [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) to preprocess the categorical and continuous features independently. Apply the [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to the continuous columns and [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) to the categorical columns.\n",
        "\n",
        "  One-hot encoding is a popular technique used to represent categorical variables numerically in machine learning models. It transforms categorical features into a binary vector representation, where each category is represented by a binary column. Here's an explanation of one-hot encoding:\n",
        "\n",
        "  When working with categorical variables, such as colors (e.g., red, blue, green) or vehicle types (e.g., car, truck, motorcycle), machine learning algorithms often require numerical inputs. However, directly assigning numerical values to categories can introduce unintended relationships or orderings between them. For example, assigning the values 0, 1, and 2 to the categories red, blue, and green may imply a sequential relationship, which is not desired.\n",
        "\n",
        "  One-hot encoding solves this problem by creating new binary columns, equal to the number of unique categories in the original feature. Each binary column represents a specific category and takes a value of 1 if the data point belongs to that category, and 0 otherwise. This encoding ensures that no implicit ordering or relationship exists between the categories.\n",
        "\n",
        "  2. Integrate the preprocessor in the previous step with Scikit-Learn's [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) model using a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
        "\n",
        "  3. Train the pipeline on the training data.\n",
        "\n",
        "  4. Evaluate the model using mean absolute error as a metric on the test data. Does the model beat the baseline?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KckTWwsiah5p"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;continuous&#x27;, StandardScaler(),\n",
              "                                 [&#x27;trip_distance&#x27;, &#x27;trip_duration&#x27;]),\n",
              "                                (&#x27;catergorical&#x27;, OneHotEncoder(),\n",
              "                                 [&#x27;VendorID&#x27;, &#x27;payment_type&#x27;, &#x27;PULocationID&#x27;,\n",
              "                                  &#x27;DOLocationID&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;continuous&#x27;, StandardScaler(),\n",
              "                                 [&#x27;trip_distance&#x27;, &#x27;trip_duration&#x27;]),\n",
              "                                (&#x27;catergorical&#x27;, OneHotEncoder(),\n",
              "                                 [&#x27;VendorID&#x27;, &#x27;payment_type&#x27;, &#x27;PULocationID&#x27;,\n",
              "                                  &#x27;DOLocationID&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">continuous</label><div class=\"sk-toggleable__content \"><pre>[&#x27;trip_distance&#x27;, &#x27;trip_duration&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">catergorical</label><div class=\"sk-toggleable__content \"><pre>[&#x27;VendorID&#x27;, &#x27;payment_type&#x27;, &#x27;PULocationID&#x27;, &#x27;DOLocationID&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder()</pre></div> </div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "ColumnTransformer(transformers=[('continuous', StandardScaler(),\n",
              "                                 ['trip_distance', 'trip_duration']),\n",
              "                                ('catergorical', OneHotEncoder(),\n",
              "                                 ['VendorID', 'payment_type', 'PULocationID',\n",
              "                                  'DOLocationID'])])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use Scikit-Learn's ColumnTransformer to preprocess the categorical and\n",
        "# continuous features independently.\n",
        "transformer = ColumnTransformer(\n",
        "    [('continuous', StandardScaler(), ['trip_distance', 'trip_duration']),\n",
        "     ('catergorical', OneHotEncoder(), ['VendorID', 'payment_type', 'PULocationID', 'DOLocationID'])]\n",
        ")\n",
        "transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "yVzxrDu6w506"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'LinearRegression' object has no attribute 'classes_'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a pipeline object containing the column transformations and regression\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m, transformer), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear_regression\u001b[39m\u001b[38;5;124m'\u001b[39m, LinearRegression())])\n\u001b[1;32m----> 5\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:1019\u001b[0m, in \u001b[0;36mPipeline.classes_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclasses_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The classes labels. Only exist if the last step is a classifier.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'classes_'"
          ]
        }
      ],
      "source": [
        "# Create a pipeline object containing the column transformations and regression\n",
        "# model.\n",
        "\n",
        "pipe = Pipeline([('transformer', transformer), ('linear_regression', LinearRegression())])\n",
        "pipe.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7Dhli3fkalIS"
      },
      "outputs": [
        {
          "ename": "DTypePromotionError",
          "evalue": "The DType <class 'numpy.dtypes.Float64DType'> could not be promoted by <class 'numpy.dtypes.TimeDelta64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.TimeDelta64DType'>)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the pipeline on the training data.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:976\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m--> 976\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    875\u001b[0m             delayed(func)(\n\u001b[0;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    882\u001b[0m             )\n\u001b[0;32m    883\u001b[0m         )\n\u001b[1;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1101\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
            "File \u001b[1;32mc:\\Users\\Clayton.Marquardt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:887\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    883\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    884\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    885\u001b[0m )\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 887\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[0;32m    890\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
            "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.Float64DType'> could not be promoted by <class 'numpy.dtypes.TimeDelta64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.TimeDelta64DType'>)"
          ]
        }
      ],
      "source": [
        "# Fit the pipeline on the training data.\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mUkcHyJpamxC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>PULocationID</th>\n",
              "      <th>DOLocationID</th>\n",
              "      <th>trip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1837655</th>\n",
              "      <td>2</td>\n",
              "      <td>3.69</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>239</td>\n",
              "      <td>0 days 00:16:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1542557</th>\n",
              "      <td>2</td>\n",
              "      <td>0.71</td>\n",
              "      <td>1</td>\n",
              "      <td>263</td>\n",
              "      <td>236</td>\n",
              "      <td>0 days 00:04:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2096656</th>\n",
              "      <td>2</td>\n",
              "      <td>1.06</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>236</td>\n",
              "      <td>0 days 00:07:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761492</th>\n",
              "      <td>2</td>\n",
              "      <td>1.22</td>\n",
              "      <td>1</td>\n",
              "      <td>237</td>\n",
              "      <td>236</td>\n",
              "      <td>0 days 00:04:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>708000</th>\n",
              "      <td>2</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>263</td>\n",
              "      <td>0 days 00:05:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607327</th>\n",
              "      <td>2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>2</td>\n",
              "      <td>170</td>\n",
              "      <td>137</td>\n",
              "      <td>0 days 00:05:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1415627</th>\n",
              "      <td>2</td>\n",
              "      <td>0.83</td>\n",
              "      <td>2</td>\n",
              "      <td>148</td>\n",
              "      <td>107</td>\n",
              "      <td>0 days 00:02:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267622</th>\n",
              "      <td>2</td>\n",
              "      <td>1.47</td>\n",
              "      <td>1</td>\n",
              "      <td>249</td>\n",
              "      <td>107</td>\n",
              "      <td>0 days 00:08:49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2353455</th>\n",
              "      <td>2</td>\n",
              "      <td>3.32</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>236</td>\n",
              "      <td>0 days 00:15:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036026</th>\n",
              "      <td>1</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>237</td>\n",
              "      <td>0 days 00:15:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>598107 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         VendorID  trip_distance  payment_type  PULocationID  DOLocationID  \\\n",
              "1837655         2           3.69             1           113           239   \n",
              "1542557         2           0.71             1           263           236   \n",
              "2096656         2           1.06             2           140           236   \n",
              "761492          2           1.22             1           237           236   \n",
              "708000          2           0.48             1           141           263   \n",
              "...           ...            ...           ...           ...           ...   \n",
              "607327          2           0.80             2           170           137   \n",
              "1415627         2           0.83             2           148           107   \n",
              "1267622         2           1.47             1           249           107   \n",
              "2353455         2           3.32             1            50           236   \n",
              "1036026         1           3.70             1           158           237   \n",
              "\n",
              "          trip_duration  \n",
              "1837655 0 days 00:16:21  \n",
              "1542557 0 days 00:04:27  \n",
              "2096656 0 days 00:07:39  \n",
              "761492  0 days 00:04:14  \n",
              "708000  0 days 00:05:06  \n",
              "...                 ...  \n",
              "607327  0 days 00:05:45  \n",
              "1415627 0 days 00:02:16  \n",
              "1267622 0 days 00:08:49  \n",
              "2353455 0 days 00:15:01  \n",
              "1036026 0 days 00:15:02  \n",
              "\n",
              "[598107 rows x 6 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions on the test data.\n",
        "X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1669p0UBHrx"
      },
      "source": [
        "Random Forest Regression and Linear Regression are two commonly used regression algorithms, each with its own advantages and suitability for different scenarios. Random Forest Regression offers several advantages over Linear Regression, including:\n",
        "\n",
        "1. **Non-linearity**: Random Forest Regressor is capable of capturing non-linear relationships between features and the target variable. In contrast, Linear Regression assumes a linear relationship between the features and the target. When faced with non-linear relationships or complex feature interactions, Random Forest Regressor can provide more accurate predictions.\n",
        "\n",
        "2. **Robustness to Outliers**: Random Forest Regressor is generally more robust to outliers compared to Linear Regression. Outliers can disproportionately impact the coefficients and predictions of Linear Regression models. However, as an ensemble of decision trees, Random Forest Regressor can mitigate the effect of outliers by averaging predictions from multiple trees.\n",
        "\n",
        "3. **Feature Importance**: Random Forest Regressor provides a measure of feature importance, which helps identify the most influential features for making predictions. This information is useful for feature selection, understanding the underlying relationships in the data, and gaining insights into the problem domain. Unlike Linear Regression, which provides coefficient values indicating the direction and magnitude of relationships, Random Forest Regressor explicitly highlights feature importance.\n",
        "\n",
        "4. **Handling of Categorical Variables**: Random Forest Regressor can effectively handle categorical variables without requiring pre-processing steps like one-hot encoding. It can directly incorporate categorical variables into the model, making it more convenient when working with mixed data types. In contrast, Linear Regression often requires categorical variables to be encoded or transformed before use.\n",
        "\n",
        "5. **Handling of High-Dimensional Data**: Random Forest Regressor can handle datasets with a large number of features (high dimensionality) by automatically selecting subsets of features during the construction of individual decision trees. This reduces the risk of overfitting, which is a concern with Linear Regression when dealing with high-dimensional data.\n",
        "\n",
        "6. **Resistance to Multicollinearity**: Random Forest Regressor is less affected by multicollinearity, which occurs when predictor variables are highly correlated. In Linear Regression, highly correlated features can lead to unstable coefficient estimates, making it challenging to interpret the individual effects of each feature. Random Forest Regressor, as an ensemble approach, is less impacted by multicollinearity because each tree is built independently.\n",
        "\n",
        "Here are your tasks:\n",
        "\n",
        "  1. Build a Random Forest Regressor model using Scikit-Learn's [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) and train it on the train data.\n",
        "\n",
        "  2. Evaluate the performance of the model on the test data using mean absolute error as a metric. Mess around with various input parameter configurations to see how they affect the model. Can you beat the performance of the linear regression model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QU4tTQKl4q_n"
      },
      "outputs": [],
      "source": [
        "# Build random forest regressor model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "P6SIX9EK5RYi"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CuYk9WBFF2X"
      },
      "source": [
        "Hyperparameter tuning plays a critical role in machine learning model development. It involves selecting the optimal values for the hyperparameters, which are configuration settings that control the behavior of the learning algorithm. Here's why hyperparameter tuning is so important in ML:\n",
        "\n",
        "1. **Optimizing Model Performance**: The choice of hyperparameters can significantly impact the model's performance. By fine-tuning the hyperparameters, we can improve the model's accuracy, precision, recall, or other performance metrics. It helps to extract the maximum predictive power from the chosen algorithm and ensures that the model is well-suited to the specific problem at hand.\n",
        "\n",
        "2. **Avoiding Overfitting and Underfitting**: Hyperparameter tuning helps strike a balance between overfitting and underfitting.\n",
        "\n",
        "3. **Exploring Model Complexity**: Hyperparameter tuning enables us to explore the complexity of the model. For instance, in algorithms like decision trees or neural networks, we can adjust the number of layers, the number of neurons, or the maximum depth of the tree. By systematically modifying these hyperparameters, we can understand how different levels of complexity impact the model's performance and find the right balance between simplicity and complexity.\n",
        "\n",
        "Note, there are multiple approaches to hyperparemeter tuning.  \n",
        "\n",
        "While grid search is the easiest to understand and implement there are many advantages of Bayesian search over grid search for hyperparameter tuning:\n",
        "\n",
        "1. **Efficiency**: Bayesian search is generally more efficient than grid search. Grid search explores all possible combinations of hyperparameter values, which can be computationally expensive and time-consuming, especially when dealing with a large number of hyperparameters or a wide range of values. Bayesian search, on the other hand, intelligently selects the next hyperparameter configuration to evaluate based on the results of previous evaluations. It focuses on areas of the hyperparameter space that are more likely to yield better performance, reducing the number of evaluations needed.\n",
        "\n",
        "2. **Flexibility**: Bayesian search is flexible in handling continuous and discrete hyperparameters. It can handle both types of hyperparameters naturally and effectively. In contrast, grid search is more suitable for discrete hyperparameters but may struggle with continuous ones, as it requires discretization or defining a finite set of values to search over.\n",
        "\n",
        "3. **Adaptive Search**: Bayesian search adapts its search strategy based on the results of previous evaluations. It maintains a probability distribution over the hyperparameter space, updating it with each evaluation. This allows it to dynamically allocate more evaluations to promising regions and explore unexplored areas. In contrast, grid search follows a fixed and predefined search grid, regardless of the results of previous evaluations.\n",
        "\n",
        "4. **Better Convergence**: Bayesian search has the potential to converge to the optimal hyperparameter configuration more quickly.\n",
        "\n",
        "Here are your tasks:\n",
        "\n",
        "  1. Perform a grid-search on a Random Forest Regressor model. Only search the space for the parameters 'n_estimators', 'max_depth', and 'min_samples_split'. Note, this can take some time to run. Make sure you set reasonable boundaries for the search space. Use Scikit-Learn's [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) method.\n",
        "\n",
        "  2. After you've identified the best parameters, train a random forest regression model using these parameters on the full training data.\n",
        "\n",
        "  3. Evaluate the model from the previous step using the test data. How does your model perform?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HlmZeNDOa1zs"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters to tune."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NWaMWOH6Kdho"
      },
      "outputs": [],
      "source": [
        "# Perform grid search to find the best hyperparameters. This could take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_JO-wsm7a58f"
      },
      "outputs": [],
      "source": [
        "# Get the best model and its parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W7ier_bt23RS"
      },
      "outputs": [],
      "source": [
        "# Fit the best classifier on the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZHPrwD41tq13"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
